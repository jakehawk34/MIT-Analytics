summary(model4)
wineTest = read.csv("wine_test.csv")
str(wineTest)
# Make predictions for these two test points
predictTest = predict(model4, newdata = wineTest)
predictTest
# Compute the R-squared value for the test set
SSE = sum((wineTest$Price - predictTest)^2)
SST = sum((wineTest$Price - mean(wine$Price)) ^2)
1 - SSE / SST
# How does a team win games? By scoring more runs than the other team.
# But how many more runs do you need?
# The Oakland A's calculated that they needed 135 more runs than their opponents to win 95 games
getwd()
baseball = read.csv("baseball.csv")
str(baseball)
baseball = read.csv("baseball.csv", stringsAsFactors = TRUE)
str(baseball)
# To confirm the claims made in Moneyball, subset the data to observations before 2002
moneyball = subset(baseball, Year < 2002)
str(moneyball)
# Create a new variable to represent the difference between runs scored and runs allowed
moneyball$RD = moneyball$RS - moneyball$RA
str(moneyball)
# Check to see if there's a relationship between Wins and Run Difference
plot(moneyball$Wins, moneyball$RD)
# Check to see if there's a relationship between Wins and Run Difference
plot(moneyball$RD, moneyball$W)
# Create a linear regression model to predict Wins using Run Difference
WinsReg = lm(W ~ RD, data = moneyball)
summary(WinsReg)
str(moneyball)
# Create a linear regression model to predict runs scored with OBP, SLG, and Batting Average (BA)
RunsReg = lm(RS ~ OBP + SLG + BA, data = moneyball)
summary(RunsReg)
# Multicollinearity between the three independent variables
# Remove BA from the model
RunsReg = lm(RS ~ OBP + SLG, data = moneyball)
summary(RunsReg)
# Create a linear regression model to predict runs allowed (RA) with OOBP and OSLG
OppRunsReg = lm(RA ~ OOBP + OSLG, data = moneyball)
summary(OppRunsReg)
-804.63 + 2737.77 * 0.311 + 1584.91 * 0.405
# Quick Question: Runs Allowed
-837.38 + 2913.6 * 0.297 + 1514 * 0.370
# Using the 2001 regular season statistics for the Oakland A's batters,
# we can predict the OBP and SLG for the 2002 season: 0.339 OBP and 0.430 SLG
# 2002 Oakland A's Runs Scored Prediction:
-804.63 + 2737.77 * 0.339 + 1584.91 * 0.430
# Using the 2001 regular season statistics for the Oakland A's pitchers,
# we can predict the OOBP and OSLG for the 2002 season: 0.307 OOBP and 0.373 OSLG
# 2002 Oakland A's Runs Allowed Prediction:
-837.38 + 2913.6 * 0.307 + 1514 * 0.373
# Predicted Runs Difference is 805 - 622 = 183 runs
# We can plug in the Oakland A's predicted Runs Difference to predict Wins for the 2002 season
# 2002 Oakland A's Wins Prediction:
80.8814 + 0.1058 * (183)
plot(teamRank, wins2012)
# Quick Question: World Series
teamRank = c(1,2,3,3,4,4,4,4,5,5)
wins2012 = c(94, 88, 95, 88, 93, 94, 98, 97, 93, 94)
wins2013 = c(97, 97, 92, 93, 92, 96, 94, 96, 92, 90)
plot(teamRank, wins2012)
lines(teamRank, wins2013)
plot(teamRank, wins2013)
plot(teamRank, wins2012)
plot(teamRank, wins2013)
NBA = read.csv("NBA_train.csv")
str(NBA)
# How many games does a team need to win in order to make the playoffs?
table(NBA$W, NBA$Playoffs)
NBA$PTSDiff = NBA$PTS - NBA$oppPTS
# Scatter plot to see if there is a linear relationship between number of wins and points difference
plot(NBA$PTSdiff, NBA$W)
# Scatter plot to see if there is a linear relationship between number of wins and points difference
plot(NBA$PTSDiff, NBA$W)
# Linear regression model to predict wins using points difference
WinsReg = lm(W ~ PTSDiff, data = NBA)
summary(WinsReg)
NBA$PTSdiff = NBA$PTS - NBA$oppPTS
# Scatter plot to see if there is a linear relationship between number of wins and points difference
plot(NBA$PTSdiff, NBA$W)
# Linear regression model to predict wins using points difference
WinsReg = lm(W ~ PTSdiff, data = NBA)
summary(WinsReg)
# Regression equation: W = 41 + 0.03259 * PTSdiff >= 42 wins
# PTSdiff
(42 - 41) / 0.03259
# Regression equation: W = 41 + 0.0326 * PTSdiff >= 42 wins
# PTSdiff
(42 - 41) / 0.0326
# Build a regression model to predict PTS
PointsReg = lm(PTS ~ X2PA + X3PA + FTA + AST + ORB + DRB + TOV + STL + BLK, data = NBA)
summary(PointsReg)
PointsReg$residuals
SSE = sum(PointsReg$residuals^2)
SSE
# Calculate the root mean squared error (RMSE)
RMSE = sqrt(SSE / nrow(NBA))
RMSE
mean(NBA$PTS)
summary(PointsReg)
# Create a new regression model to predict PTS removing TOV
# because its p-value is the highest of the independent variables
PointsReg = lm(PTS ~ X2PA + X3PA + FTA + AST + ORB + DRB + STL + BLK, data = NBA)
summary(PointsReg)
# Build a regression model to predict PTS
PointsReg = lm(PTS ~ X2PA + X3PA + FTA + AST + ORB + DRB + TOV + STL + BLK, data = NBA)
summary(PointsReg)
# Create a new regression model to predict PTS removing TOV
# because its p-value is the highest of the independent variables
PointsReg2 = lm(PTS ~ X2PA + X3PA + FTA + AST + ORB + DRB + STL + BLK, data = NBA)
summary(PointsReg2)
# Create a new regression model to predict PTS removing DRB
# because its p-value is the highest of the remaining independent variables
PointsReg3 = lm(PTS ~ X2PA + X3PA + FTA + AST + ORB + STL + BLK, data = NBA)
summary(PointsReg3)
# Create a new regression model to predict PTS removing BLK
# because its p-value is the highest of the remaining independent variables
PointsReg4 = lm(PTS ~ X2PA + X3PA + FTA + AST + ORB + STL, data = NBA)
summary(PointsReg4)
# Calculate the SSE and RMSE for PointsReg4 and compare them with the values from the original model
SSE_4 = sum(PointsReg4$residuals^2)
SSE_4
RMSE_4 = sqrt(SSE_4 / nrow(NBA))
RMSE_4
# Load the NBA testing set
NBA_test = read.csv("NBA_test.csv")
# Predict how many points there will be in the 2012-2013 NBA season
PointsPredictions = predict(PointsReg4, newdata = NBA_test)
# Compute the out of sample R-squared
SSE = sum((PointsPredictions - NBA_test$PTS)^2)
SST = sum((mean(NBA$PTS) - NBA_test$PTS)^2)
R2 = 1 - SSE / SST
RMSE = sqrt(SSE / nrow(NBA_test))
RMSE
setwd("~/Documents/GitHub/MIT-Analytics/Unit 2")
ClimateChange = read.csv("climate_change.csv")
ClimateChange = read.csv("climate_change.csv", stringsAsFactors = TRUE)
str(ClimateChange)
UpTo2006 = susbet(ClimateChange, Year <= 2006)
UpTo2006 = subset(ClimateChange, Year <= 2006)
After2006 = subset(ClimateChange, Year > 2006)
# Linear regression model to predict Temp
# using MEI, CO2, CH4, N2O, CFC.11, CFC.12, TSI, and Aerosols as independent variables
TempReg = lm(Temp ~ MEI + CO2 + CH4 + N2O + CFC.11 + CFC.12 + TSI + Aerosols, data = UpTo2006)
summary(TempReg)
# Training set of data up to and including 2006
train = subset(ClimateChange, Year <= 2006)
# Testing set of data after 2006
test = subset(ClimateChange, Year > 2006)
# Linear regression model to predict Temp
# using MEI, CO2, CH4, N2O, CFC.11, CFC.12, TSI, and Aerosols as independent variables
TempReg = lm(Temp ~ MEI + CO2 + CH4 + N2O + CFC.11 + CFC.12 + TSI + Aerosols, data = train)
summary(TempReg) # Multiple R-squared: 0.7509
cor(TempReg)
cor(train)
# Compute the correlations between all the variables in the training set.
cor(train)
# Build a new model to predict Temp with only MEI, TSI, Aerosols and N2O as independent variables
TempReg2 = lm(Temp ~ MEI + TSI + Aerosols + N2O, data = train)
summary(TempReg2)
# Use the step function in R to derive a new model, with the full model as the initial model
step(TempReg)
# Use the step function in R to derive a new model, with the full model as the initial model
TempStep = step(TempReg)
summary(TempStep)
# Using the model produced from the step function,
# calculate temperature predictions for the testing data set, using the predict function.
TempPredictions = predict(TempStep, newdata = test)
summary(TempPredictions)
SSE = sum((TempPredictions - test$Temp)^2)
SST = sum((mean(train$PTS) - test$Temp)^2)
SST = sum((mean(train$Temp) - test$Temp)^2)
R2 = 1 - SSE / SST
setwd("~/Documents/GitHub/MIT-Analytics/Unit 2")
setwd("~/Documents/GitHub/MIT-Analytics/Unit 2")
train = read.csv("pisa2009train.csv")
test = read.csv("pisa2009test.csv")
pisaTrain = read.csv("pisa2009train.csv")
pisaTest = read.csv("pisa2009test.csv")
rm(test, train)
# Average reading test score of males
tapply(pisaTrain$readingScore, pisaTrain$male, mean)
pisaTrain = read.csv("pisa2009train.csv", stringsAsFactors = TRUE)
pisaTest = read.csv("pisa2009test.csv", stringsAsFactors = TRUE)
# Average reading test score of males
tapply(pisaTrain$readingScore, pisaTrain$male, mean)
# Males: 483.5325
# Males: 483.5325
# Females: 512.9406
summary(pisaTrain)
pisaTrain = na.omit(pisaTrain)
pisaTest = na.omit(pisaTest)
# Set the reference level of the factor by typing the following two lines in your R console:
pisaTrain$raceeth = relevel(pisaTrain$raceeth, "White")
pisaTest$raceeth = relevel(pisaTest$raceeth, "White")
# Now, build a linear regression model (call it lmScore) using the training set to predict readingScore using all the remaining variables.
# It would be time-consuming to type all the variables, but R provides the shorthand notation "readingScore ~ ."
# to mean "predict readingScore using all the other variables in the data frame."
# The period is used to replace listing out all of the independent variables.
lmScore = lm(readingScore ~ .)
# Now, build a linear regression model (call it lmScore) using the training set to predict readingScore using all the remaining variables.
# It would be time-consuming to type all the variables, but R provides the shorthand notation "readingScore ~ ."
# to mean "predict readingScore using all the other variables in the data frame."
# The period is used to replace listing out all of the independent variables.
lmScore = lm(readingScore ~ ., data = pisaTrain)
summary(lmScore)
# Training-set root-mean squared error (RMSE) of lmScore
SSE = sum(lmScore$residuals^2)
RMSE = sqrt(SSE / nrow(pisaTrain))
RMSE
# Compare predicted score of grade 11 student A and grade 9 student B
29.542707 * 11 - 29.542707 * 9
predTest = predict(lmScore, newdata = pisaTest)
summary(predTest)
range(predTest)
max(predTest) - min(predTest)
SST_test = sum((mean(pisaTrain$readingScore) - pisaTest$readingScore)^2)
RMSE_test = sqrt(SSE_test / nrow(pisaTest))
SSE_test = sum((predTest - pisaTest$readingScore)^2)
SST_test = sum((mean(pisaTrain$readingScore) - pisaTest$readingScore)^2)
RMSE_test = sqrt(SSE_test / nrow(pisaTest))
SSE_test
RMSE_test
SST_test
predict(lmScore)
mean(predict(lmScore))
baseline = mean(pisaTrain$readingScore)
# test-set R-squared value of lmScore
R2_test = 1 - SSE_test / SST_test
R2_test
getwd()
FluTrain = read.csv("FluTrain.csv")
str(FluTrain)
summary(FluTrain)
max(FluTrain$ILI)
which.max(FluTrain$ILI)
FluTrain[303]
FluTrain[0]
FluTrain
which.max(FluTrain$Queries)
max(FluTrain$Queries)
FluTrain$Week[303]
# Plot the histogram of the dependent variable, ILI
hist(FluTrain$ILI)
# Plot the natural logarithm of ILI versus Queries. What does the plot suggest?
plot(log(FluTrain$Week), FluTrain$Queries)
# Plot the natural logarithm of ILI versus Queries. What does the plot suggest?
plot(log(FluTrain$ILI), FluTrain$Queries)
# Plot the natural logarithm of ILI versus Queries. What does the plot suggest?
plot(FluTrain$Queries, log(FluTrain$ILI))
FluTrend1 = lm(log(ILI) ~ Queries, data = FluTrain)
summary(FluTrend1)
# What is the relationship we infer from our problem?
cor(FluTrain)
# What is the relationship we infer from our problem?
cor(FluTrain$ILI, FluTrain$Queries)
# What is the relationship we infer from our problem?
cor(FluTrain$ILI, FluTrain$Queries)^2
# What is the relationship we infer from our problem?
log(1 / cor(FluTrain$ILI, FluTrain$Queries))
# What is the relationship we infer from our problem?
exp(-0.5 * cor(FluTrain$ILI, FluTrain$Queries))
# What is the relationship we infer from our problem?
cor(log(FluTrain$ILI), FluTrain$Queries)
# What is the relationship we infer from our problem?
cor(log(FluTrain$ILI), FluTrain$Queries)^2
FluTest = read.csv("FluTest.csv")
PredTest1 = exp(predict(FluTrend1, newdata=FluTest))
?which
which(FluTest$Week = 2012-03-11)
which(FluTest$Week == 2012-03-11)
which(FluTest$Week == 2012-03-11 - 2012-03-17)
which(FluTest$Week == 2012-03-11 - 2012-03-17)
FluTest$Week == 2012-03-11 - 2012-03-17
FluTest$Week
FluTest$Week[11]
FluTest$ILI[11]
which(FluTest$Week == "2012-03-11 - 2012-03-17")
PredTest1[11]
# Relative error betweeen the estimate (our prediction) and the observed value for the week of March 11, 2012
FluTest$ILI[11]
estimate = PredTest1[11]
# Relative error betweeen the estimate (our prediction) and the observed value for the week of March 11, 2012
observed = FluTest$ILI[11]
(observed - estimate) / observed
# What is the Root Mean Square Error (RMSE) between our estimates
# and the actual observations for the percentage of ILI-related physician visits, on the test set
SSE = sum((FluTest$ILI - PredTest1)^2)
RMSE = sqrt(SSE / nrow(PredTest1))
RMSE = sqrt(SSE / nrow(FluTest))
sqrt(mean((PredTest1-FluTest$ILI)^2))
install.packages("zoo")
library(zoo)
ILILag2 = lag(zoo(FluTrain$ILI), -2, na.pad=TRUE)
FluTrain$ILILag2 = coredata(ILILag2)
summary(FluTrain)
# Plot the log of ILILag2 against the log of ILI
plot(FluTrain$ILILag2, FluTrain$ILI)
# Plot the log of ILILag2 against the log of ILI
plot(log(FluTrain$ILILag2), log(FluTrain$ILI))
# Train a linear regression model on the FluTrain dataset to predict the log of the ILI variable using the Queries variable
# as well as the log of the ILILag2 variable
FluTrend2 = lm(log(ILI) ~ Queries + log(ILILag2), data = FluTrain)
summary(FluTrend2)
# Modify the code from the previous subproblem to add an ILILag2 variable to the FluTest data frame.
ILILag2Test = lag(zoo(FluTest$ILI), -2, na.pad=TRUE)
FluTest$ILILag2 = coredata(ILILag2Test)
summary(FluTest)
nrow(FluTrain)
FluTrain[417]
x
x = FluTrain[417]
x
FluTrain$Week[417]
FluTrain$Week[416]
FluTest$Week[1]
FluTest$ILI[1]
FluTest$ILILag[1]
FluTest$ILILag2[2]
FluTest$ILILag2[1]
FluTrain$ILI[417]
FluTest$ILILag2[1] = FluTrain$ILI[416]
FluTest$ILILag2[2] = FluTrain$ILI[417]
FluTest$ILILag2[1] # First observation in 2012
FluTest$ILILag2[2] # Second observation in 2012
# Obtain test set predictions of the ILI variable from the FluTrend2 model
PredTest2 = exp(predict(FluTrend2, newdata = FluTest)
SSE_2 = sum((PredTest2 - FluTest$ILI)^2)
# Obtain test set predictions of the ILI variable from the FluTrend2 model
PredTest2 = exp(predict(FluTrend2, newdata = FluTest)
RMSE_2 =
sqrt(mean(PredTest2 - FluTest$ILI)^2)
# Obtain test set predictions of the ILI variable from the FluTrend2 model
PredTest2 = exp(predict(FluTrend2, newdata = FluTest))
SSE_2 = sum((PredTest2 - FluTest$ILI)^2)
RMSE_2 = sqrt(SSE_2 / nrow(FluTest))
sqrt(mean(PredTest2 - FluTest$ILI)^2)
sqrt(mean((PredTest2 - FluTest$ILI)^2))
# Which model obtained the best test-set RMSE?
RMSE_2 > RMSE
# Which model obtained the best test-set RMSE?
RMSE_2 < RMSE
data(state)
statedata = cbind(data.frame(state.x77), state.abb, state.area, state.center,  state.division, state.name, state.region)
str(statedata)
# Plot all of the states' centers with latitude on the y axis (the "y" variable in our dataset) and longitude on the x axis (the "x" variable in our dataset)
plot(statedata.x, statedata.y)
# Plot all of the states' centers with latitude on the y axis (the "y" variable in our dataset) and longitude on the x axis (the "x" variable in our dataset)
plot(statedata$x, statedata$y)
# Using the tapply command, determine which region of the US (West, North Central, South, or Northeast)
# has the highest average high school graduation rate of all the states in the region:
tapply(statedata$HS.Grad, statedata$state.region, summary)
# Using the tapply command, determine which region of the US (West, North Central, South, or Northeast)
# has the highest average high school graduation rate of all the states in the region:
tapply(statedata$HS.Grad, statedata$state.region, mean)
# Make a boxplot of the murder rate by region
?boxplot
# Make a boxplot of the murder rate by region
boxplot(statedata$Murder ~ statedata$state.region)
# You should see that there is an outlier in the Northeast region of the boxplot you just generated.
# Which state does this correspond to?
sort(subset(statedata, state.region == "Northeast"))
# You should see that there is an outlier in the Northeast region of the boxplot you just generated.
# Which state does this correspond to?
subset(statedata, state.region == "Northeast")
# You should see that there is an outlier in the Northeast region of the boxplot you just generated.
# Which state does this correspond to?
subset(statedata, state.region == "Northeast" & Murder = max(Murder))
# You should see that there is an outlier in the Northeast region of the boxplot you just generated.
# Which state does this correspond to?
subset(statedata, state.region == "Northeast" & Murder == max(Murder))
# You should see that there is an outlier in the Northeast region of the boxplot you just generated.
# Which state does this correspond to?
subset(statedata, state.region == "Northeast")
# You should see that there is an outlier in the Northeast region of the boxplot you just generated.
# Which state does this correspond to?
NortheastData = subset(statedata, state.region == "Northeast")
# Build a model to predict life expectancy by state using the state statistics we have in our dataset
LifeExpReg = lm(Life.Exp ~ Population + Income + Illiteracy + Murder + HS.Grad + Frost + Area, data = statedata)
summary(LifeExpReg)
plot(statedata$Income, statedata$Life.Exp)
# You should be able to find a good model with only 4 independent variables, instead of the original 7.
# Which variables does this model contain?
LifeExpReg2 = lm(Life.Exp ~ Population + Illiteracy + Murder + HS.Grad + Frost + Area, data = statedata)
summary(LifeExpReg2)
# You should be able to find a good model with only 4 independent variables, instead of the original 7.
# Which variables does this model contain?
LifeExpReg2 = lm(Life.Exp ~ Population + Income + Illiteracy + Murder + HS.Grad + Frost, data = statedata)
summary(LifeExpReg2)
LifeExpReg3 = lm(Life.Exp ~ Population + Income + Murder + HS.Grad + Frost, data = statedata)
summary(LifeExpReg3)
LifeExpReg4 = lm(Life.Exp ~ Population + Murder + HS.Grad + Frost, data = statedata)
summary(LifeExpReg4)
# Which state do we predict to have the lowest life expectancy? (Hint: use the sort function)
predict(LifeExpReg4)
# Which state do we predict to have the lowest life expectancy? (Hint: use the sort function)
which.min(predict(LifeExpReg4))
# Which state do we predict to have the lowest life expectancy? (Hint: use the sort function)
sort(predict(LifeExpReg4))
# Which state do we predict to have the lowest life expectancy? (Hint: use the sort function)
which.min(predict(LifeExpReg4))
# Which state actually has the lowest life expectancy? (Hint: use the which.min function)
which.min(statedata$Life.Exp)
# Which state actually has the lowest life expectancy? (Hint: use the which.min function)
min(statedata$Life.Exp)
statedata$state.abb[40]
statedata$state.name[40] # South Carolina
# Which state do we predict to have the highest life expectancy?
which.max(predict(LifeExpReg4))
# Which state actually has the highest life expectancy?
which.max(statedata$Life.Exp)
statedata$stae.name[11]
statedata$state.name[11]
# For which state do we make the smallest absolute error?
LifeExpReg4$residuals
# For which state do we make the smallest absolute error?
min(LifeExpReg4$residuals)
# For which state do we make the smallest absolute error?
which.min(LifeExpReg4$residuals)
# For which state do we make the smallest absolute error?
which.min(abs(LifeExpReg4$residuals))
# For which state do we make the largest absolute error?
which.max(abs(LifeExpReg4$residuals))
setwd("~/Documents/GitHub/MIT-Analytics/Unit 2")
elantra = read.csv("elantra.csv")
train = subset(elantra, elantra$Year <= 2012)
test = subset(elantra, elantra$Year > 2012)
summary(elantra)
# Build a linear regression model to predict monthly Elantra sales
# using Unemployment, CPI_all, CPI_energy and Queries as the independent variables
SalesReg = lm(ElantraSales ~ Unemployment + CPI_all + CPI_energy + Queries, data = train)
summary(SalesReg)
# To incorporate the seasonal effect due to the month, build a new linear regression model that predicts monthly Elantra sales
# using Month as well as Unemployment, CPI_all, CPI_energy and Queries.
SalesReg2 = lm(ElantraSales ~ Month + Unemployment + CPI_all + CPI_energy + Queries, data = train)
summary(SalesReg2)
148330.49 * 2
110.69 * 2
# In the new model, given two monthly periods that are otherwise identical in Unemployment, CPI_all, CPI_energy and Queries,
# what is the absolute difference in predicted Elantra sales given that one period is in January and one is in May?
110.69 * 4
?as.factor
# Re-run the regression with the Month variable modeled as a factor variable.
elantra$MonthF = as.factor(elantra$Month)
SalesReg3 = lm(ElantraSales ~ MonthF + Unemployment + CPI_all + CPI_energy + Queries, data = train)
summary(elantra)
# Re-run the regression with the Month variable modeled as a factor variable.
train$MonthFactor = as.factor(train$Month)
test$MonthFactor = as.factor(test$Month)
SalesReg3 = lm(ElantraSales ~ MonthFactor + Unemployment + CPI_all + CPI_energy + Queries, data = train)
summary(SalesReg3)
summary(SalesReg2)
summary(SalesReg3)
# Which of the following variables is CPI_energy highly correlated with?
cor(train)
# Which of the following variables is CPI_energy highly correlated with?
?cor
# Which of the following variables is CPI_energy highly correlated with?
ElantraCor <- cor(train)
# Which of the following variables is CPI_energy highly correlated with?
train
# Which of the following variables is CPI_energy highly correlated with?
cor(train$Queries)
# Which of the following variables is CPI_energy highly correlated with?
cor(train$CPI_energy)
# Which of the following variables is CPI_energy highly correlated with?
cor(ElantraTrain[c("Unemployment","Month","Queries","CPI_energy","CPI_all")])
# Which of the following variables is CPI_energy highly correlated with?
cor(train[c("Unemployment","Month","Queries","CPI_energy","CPI_all")])
# Which of the following variables is Queries highly correlated with?
cor(train[c("Unemployment","Month","Queries","CPI_energy","CPI_all")])
# Let us now simplify our model. We will do this by iteratively removing variables, one at a time.
SalesReg4 = lm(ElantraSales ~ MonthFactor + Unemployment + CPI_all + CPI_energy, data = train)
summary(SalesReg4)
# Using the model from Problem 6.1, make predictions on the test set.
# What is the sum of squared errors of the model on the test set?
PredTest1 = predict(SalesReg4, newdata = test)
SSE = sum((PredTest1 - test$ElantraSales)^2)
SSE
# What would the baseline method predict for all observations in the test set?
mean(train$ElantraSales)
# What is the test set R-Squared?
SST = sum((mean$ElantraSales - PredTest1)^2)
# What is the test set R-Squared?
SST = sum((mean(test$ElantraSales) - PredTest1)^2)
R2 = 1 - SSE / SST
R2
# What is the test set R-Squared?
SST = sum((mean(train$ElantraSales) - PredTest1)^2)
R2 = 1 - SSE / SST
# What is the test set R-Squared?
SST = sum((mean(train$ElantraSales) - test$ElantraSales)^2)
R2 = 1 - SSE / SST
R2
# What is the largest absolute error that we make in our test set predictions?
max(abs(PredTest1 - test$ElantraSales))
# In which period (Month,Year pair) do we make the largest absolute error in our prediction?
which(max(abs(PredTest1 - test$ElantraSales)))
# In which period (Month,Year pair) do we make the largest absolute error in our prediction?
abs(PredTest1 - test$ElantraSales)
test[14]
test$Month[14]
test$Month[14], test$Year[14]
test$Year[14]
# In which period (Month,Year pair) do we make the largest absolute error in our prediction?
which.max(abs(PredTest1 - test$ElantraSales))
# In which period (Month,Year pair) do we make the largest absolute error in our prediction?
which.max(abs(PredTest1 - test$ElantraSales))
test$Month[5]
c(test$Month[5], test$Year[5])
