# Some of the countries are missing.
table(intlall$Citizenship)
table(world_map$region)
table(world_map$group)
# Load ggplot library
library(ggplot2)
# Load our data, which lives in intl.csv
intl = read.csv("intl.csv")
str(intl)
# We want to make a bar plot with region on the X axis
# and Percentage on the y-axis.
ggplot(intl, aes(x=Region, y=PercentOfIntl)) +
geom_bar(stat="identity") +
geom_text(aes(label=PercentOfIntl))
# Make Region an ordered factor
# We can do this with the re-order command and transform command.
intl = transform(intl, Region = reorder(Region, -PercentOfIntl))
# Look at the structure
str(intl)
# Make the percentages out of 100 instead of fractions
intl$PercentOfIntl = intl$PercentOfIntl * 100
# Make the plot
ggplot(intl, aes(x=Region, y=PercentOfIntl)) +
geom_bar(stat="identity", fill="dark blue") +
geom_text(aes(label=PercentOfIntl), vjust=-0.4) +
ylab("Percent of International Students") +
theme(axis.title.x = element_blank(), axis.text.x = element_text(angle = 45, hjust = 1))
# Load the ggmap package
library(ggmap)
# Load in the international student data
intlall = read.csv("intlall.csv",stringsAsFactors=FALSE)
# Lets look at the first few rows
head(intlall)
# Those NAs are really 0s, and we can replace them easily
intlall[is.na(intlall)] = 0
# Now lets look again
head(intlall)
# Load the world map
world_map = map_data("world")
str(world_map)
# Lets merge intlall into world_map using the merge command
world_map = merge(world_map, intlall, by.x ="region", by.y = "Citizenship")
str(world_map)
# Plot the map
ggplot(world_map, aes(x=long, y=lat, group=group)) +
geom_polygon(fill="white", color="black") +
coord_map("mercator")
# Reorder the data
world_map = world_map[order(world_map$group, world_map$order),]
# Redo the plot
ggplot(world_map, aes(x=long, y=lat, group=group)) +
geom_polygon(fill="white", color="black") +
coord_map("mercator")
# Lets look for China
table(intlall$Citizenship)
# Lets "fix" that in the intlall dataset
intlall$Citizenship[intlall$Citizenship=="China (People's Republic Of)"] = "China"
# We'll repeat our merge and order from before
world_map = merge(map_data("world"), intlall,
by.x ="region",
by.y = "Citizenship")
world_map = world_map[order(world_map$group, world_map$order),]
ggplot(world_map, aes(x=long, y=lat, group=group)) +
geom_polygon(aes(fill=Total), color="black") +
coord_map("mercator")
# We can try other projections - this one is visually interesting
ggplot(world_map, aes(x=long, y=lat, group=group)) +
geom_polygon(aes(fill=Total), color="black") +
coord_map("ortho", orientation=c(20, 30, 0))
ggplot(world_map, aes(x=long, y=lat, group=group)) +
geom_polygon(aes(fill=Total), color="black") +
coord_map("ortho", orientation=c(-37, 175, 0))
intl = read.csv("intl.csv")
str(intl)
ggplot(intl, aes(x=Region, y=PercentOfIntl)) +
geom_bar(stat="identity") +
geom_text(aes(label=PercentOfIntl))
# What we need to do is make Region an ordered factor instead of an unordered factor.
# Region is reordered based on decreasing order of PercentOfIntl.
intl = transform(intl, Region = reorder(Region, -PercentOfIntl))
str(intl)
# Multiply all values by 100 so they're no longer between 0 and 1.
intl$PercentOfIntl = intl$PercentOfIntl * 100
# So we've got our labels vjust-ed above the columns.
# The bars themselves are dark blue.
# The numbers are now between 0 and 100, instead of zero and one.
# We can read all the text labels.
# And it's generally a lot more readable than the pie plot or our original ggplot, at that.
ggplot(intl, aes(x=Region, y=PercentOfIntl)) +
geom_bar(stat="identity", fill="dark blue") +
geom_text(aes(label=PercentOfIntl), vjust=-0.4) +
ylab("Percent of International Students") +
theme(axis.title.x = element_blank(), axis.text.x = element_text(angle = 45, hjust = 1))
intlall = read.csv("intlall.csv", stringsAsFactors = FALSE)
str(intlall)
# Change all NA's to zeros
intlall[is.na(intlall)] = 0
str(intlall)
# Load the world map
world_map = map_data("world")
str(world_map)
# Merge the world_map and intlall data frames into one
world_map = merge(world_map, intlall, by.x="region", by.y="Citizenship")
str(world_map)
# We have to reorder the data in the correct order to create a correct map.
# Order the rows based on the group variable and then the order variable.
# The group is equivalent to the country basically.
# The order is the correct order for the border points.
world_map = world_map[order(world_map$group, world_map$order),]
ggplot(world_map, aes(x=long, y=lat, group=group)) +
geom_polygon(aes(fill="white"), color="black") +
coord_map("mercator")
# Some of the countries are missing.
table(intlall$Citizenship)
# Change the MIT data frame so China (People'S Republic Of) to China
intlall$Citizenship[intlall$Citizenship == "China (People's Republic Of)"] = "China"
table(intlall$Citizenship)
# Merge and reorder again
world_map = merge(map_data("world"), intlall, by.x="region", by.y="Citizenship")
world_map = world_map[order(world_map$group, world_map$order),]
str(world_map)
# Plot the map
ggplot(world_map, aes(x=long, y=lat, group=group)) +
geom_polygon(aes(fill=Total), color="black") +
coord_map("mercator")
ggplot(world_map[abs(world_map$long) < 180,], aes(x=long, y=lat, group=group)) +
geom_polygon(aes(fill=Total), color="black") +
coord_map("mercator")
# Orthographic projection
ggplot(world_map[abs(world_map$long) < 180,], aes(x=long, y=lat, group=group)) +
geom_polygon(aes(fill=Total), color="black") +
coord_map("ortho", orientation=c(20, 30, 0))
ggplot(world_map, aes(x=long, y=lat, group=group)) +
geom_polygon(aes(fill=Total), color="black") +
coord_map("ortho", orientation=c(-37, 175, 0))
ggplot(world_map, aes(x=long, y=lat, group=group)) +
geom_polygon(aes(fill=Total), color="black") +
coord_map("ortho", orientation=c(50, 20, 0))
ggplot(world_map, aes(x=long, y=lat, group=group)) +
geom_polygon(aes(fill=Total), color="black") +
coord_map("ortho", orientation=c(50, 50, 0))
ggplot(world_map, aes(x=long, y=lat, group=group)) +
geom_polygon(aes(fill=Total), color="black") +
coord_map("ortho", orientation=c(100, 20, 0))
ggplot(world_map, aes(x=long, y=lat, group=group)) +
geom_polygon(aes(fill=Total), color="black") +
coord_map("ortho", orientation=c(0, 0, 0))
ggplot(world_map, aes(x=long, y=lat, group=group)) +
geom_polygon(aes(fill=Total), color="black") +
coord_map("ortho", orientation=c(-10, 0, 0))
ggplot(world_map, aes(x=long, y=lat, group=group)) +
geom_polygon(aes(fill=Total), color="black") +
coord_map("ortho", orientation=c(-50, 0, 0))
ggplot(world_map, aes(x=long, y=lat, group=group)) +
geom_polygon(aes(fill=Total), color="black") +
coord_map("ortho", orientation=c(20, -50, 0))
ggplot(world_map, aes(x=long, y=lat, group=group)) +
geom_polygon(aes(fill=Total), color="black") +
coord_map("ortho", orientation=c(20, -75, 0))
library(reshape2)
# Scales
households = read.csv("households.csv")
str(households)
households[,1:2]
# Now, let's look at the first few rows of our melted households data frame.
head(melt(hosueholds, id="Year"))
# Now, let's look at the first few rows of our melted households data frame.
head(melt(households, id="Year"))
# First three columns of the data frame
households[,1:3]
# First ten rows of our melted households data frame.
melt(households, id="Year")[1:10]
# First ten rows of our melted households data frame.
melt(households, id="Year")[,1:10]
# First ten rows of our melted households data frame.
melt(households, id="Year")[1:10,]
# First ten rows of our melted households data frame.
melt(households, id="Year")[1:10,3]
# First ten rows of our melted households data frame.
melt(households, id="Year")[1:10,]
# Plot the melted data frame
ggplot(melt(households, id="Year"), aes(x=Year, y=Value, color=variable)) +
geom_line(size=2) +
geom_point(size=5) +
ylab("Percentage of Households")
# Plot the melted data frame
ggplot(melt(households, id="Year"), aes(x=Year, y=value, color=variable)) +
geom_line(size=2) +
geom_point(size=5) +
ylab("Percentage of Households")
statesMap = map_data("state")
str(statesMap)
table(statesMap$group)
# Draw a map of the United States
ggplot(statesMap, aes(x=long, y=lat, group=group)) + geom_polygon(fill="white", color="black")
# Color the map according to our 2012 presidential election predictions from Unit 3.
polling = read.csv("PollingImputed.csv")
split = sample.split(polling, SplitRatio = 0.7)
train = subset(polling, split == TRUE)
test = subset(polling, split ==  FALSE)
63/145
str(polling)
split = sample.split(polling$Republican, SplitRatio = 0.7)
train = subset(polling, split == TRUE)
test = subset(polling, split ==  FALSE)
43/145
Train = subset(polling, split == TRUE)
Test = subset(polling, split ==  FALSE)
rm(train, test)
# Create a logistic regression model
mod2 = glm(Republican~SurveyUSA+DiffCount, data=Train, family="binomial")
TestPrediction = predict(mod2, newdata=Test, type="response")
TestPredictionBinary = as.numeric(TestPrediction > 0.5)
# Now, put the predictions and state labels in a data.frame so that we can use ggplot
predictionDataFrame = data.frame(TestPrediction, TestPredictionBinary, Test$State)
table(predictionDataFrame$TestPredictionBinary)
mean(predictionDataFrame$TestPrediction)
rm(split)
Train = subset(polling, Year < 2012)
Test = subset(polling, Year == 2012)
# Create a logistic regression model
mod2 = glm(Republican~SurveyUSA+DiffCount, data=Train, family="binomial")
TestPrediction = predict(mod2, newdata=Test, type="response")
# Create a vector of Republican/Democrat predictions
TestPredictionBinary = as.numeric(TestPrediction > 0.5)
# Now, put the predictions and state labels in a data.frame so that we can use ggplot
predictionDataFrame = data.frame(TestPrediction, TestPredictionBinary, Test$State)
table(predictionDataFrame$TestPredictionBinary)
mean(predictionDataFrame$TestPrediction)
table(TestPredictionBinary)
mean(TestPrediction)
# Convert the Test.State variable to lowercase
predictionDataFrame$region = tolower(predictionDataFrame$Test.State)
str(predictionDataFrame)
str(statesMap)
# Merge the two data frames
predictionMap = merge(statesMap, predictionDataFrame, by="region")
# Make sure that the observations are in order so that the map is drawn correctly.
predictionMap = predictionMap[order(predictionMap$order),]
?merge
# Now we can color the United States based on our predictions.
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary)) + geom_polygon(color = "black")
# Replot the map with discrete outcomes
# Blue for Democrat, Red for Republican
ggplot(predictionMap, aes(x = long, y =lat, group = group, fill = TestPredictionBinary)) +
geom_polygon(color="black") +
scale_fill_gradient(low="blue", high="red", guide="legend", breaks=c(0,1), labels=c("Democrat", "Republican"), name="Prediction 2012")
# Alternatively, we could plot the probabilities instead of the binary predictions.
ggplot(predictionMap, aes(x = long, y =lat, group = group, fill = TestPrediction)) +
geom_polygon(color="black") +
scale_fill_gradient(low="blue", high="red", guide="legend", breaks=c(0,1), labels=c("Democrat", "Republican"), name="Prediction 2012")
# Alternatively, we could plot the probabilities instead of the binary predictions.
ggplot(predictionMap, aes(x = long, y =lat, group = group, fill = TestPrediction)) +
geom_polygon(color="black") +
scale_fill_gradient(low="grey", high="black", guide="legend", breaks=c(0,1), labels=c("Democrat", "Republican"), name="Prediction 2012")
# Alternatively, we could plot the probabilities instead of the binary predictions.
ggplot(predictionMap, aes(x = long, y =lat, group = group, fill = TestPrediction)) +
geom_polygon(color="black") +
scale_fill_gradient(low="violet", high="red", guide="legend", breaks=c(0,1), labels=c("Democrat", "Republican"), name="Prediction 2012")
# Alternatively, we could plot the probabilities instead of the binary predictions.
ggplot(predictionMap, aes(x = long, y =lat, group = group, fill = TestPrediction)) +
geom_polygon(color="black") +
scale_fill_gradient(low="black", high="red", guide="legend", breaks=c(0,1), labels=c("Democrat", "Republican"), name="Prediction 2012")
# Alternatively, we could plot the probabilities instead of the binary predictions.
ggplot(predictionMap, aes(x = long, y =lat, group = group, fill = TestPrediction)) +
geom_polygon(color="black") +
scale_fill_gradient(low="blue", high="red", guide="legend", breaks=c(0,1), labels=c("Democrat", "Republican"), name="Prediction 2012")
table(TestPrediction, TestPredictionBinary)
# What was our predicted probability for the state of Florida?
predictionMap[predictionMap$region=="florida"]
# What was our predicted probability for the state of Florida?
predictionDataFrame[predictionDataFrame$region=="florida"]
str(predictionDataFrame)
# What was our predicted probability for the state of Florida?
subset(predictionDataFrame, region="florida")
# What was our predicted probability for the state of Florida?
predictionDataFrame
?geom_polygon
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPrediction)) +
geom_polygon(color = "black", linetype=3) +
scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
# size = 3
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPrediction)) +
geom_polygon(color = "black", size=3) +
scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
#
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPrediction)) +
geom_polygon(color = "black", alpha=0.3) +
scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
users = read.csv("user.csv")
users = read.csv("users.csv")
edges = read.csv("edges.csv")
str(users)
str(edges)
table(edges$V2, users$id)
table(edges$V2)
table(edges$V2, edges$V2)
tapply(edges$V1, edges$V2, mean)
tapply(edges$V1, mean)
mean(edges$V2)
tapply(edges$V1, edges$V2, sum)
tapply(edges$V1, edges$V1, sum)
tapply(edges$V1, edges$V1, round(sum/edges$V1))
tapply(edges$V1, edges$V1, sum)
table(edges$V1[1], edges$V2)
table(edges$V1 == edges$V1[1], edges$V2)
str(edges)
table(edges$V1 == edges$V1[1], edges$V2)
table(edges$V1 == edges$V1[2], edges$V2)
sum(table(edges$V1 == edges$V1[1], edges$V2))
# Average number of friends per user
nrow(edges) / nrow(users)
# Average number of friends per user
2 * nrow(edges) / nrow(users)
table(users$locale)
str(users)
str(edges)
table(users$school)
head(users$school)
table(users$school, users$gender)
# Install and load the igraph package
install.packages("igraph")
library(igraph)
?graph.data.frame
g = graph.data.frame(edges, FALSE, users)
plot(g, vertex.size=5, vertex.label=NA)
# We can use degree(g) to compute the degree of all the nodes in our graph g.
degree(g)
table(degree(g) >= 10)
# We will change the size of the vertices so the vertices with high degrees are larger.
V(g)$size = degree(g)/2+2
plot(g, vertex.label=NA)
# What is the largest size we assigned to any node in our graph?
max(V(g)$size)
# What is the smallest size we assigned to any node in our graph?
min(V(g)$size)
V(g)$color = "black"
V(g)$color[V(g)$gender == "A"] = "red"
V(g)$color[V(g)$gender == "B"] = "gray"
plot(g, vertex.label=NA)
# Now, color the vertices based on the school that each user in our network attended.
V(g)$color = "black"
V(g)$color[V(g)$school == "A"] = "red"
V(g)$color[V(g)$school == "AB"] = "blue"
plot(g, vertex.label=NA)
V(g)$color[V(g)$school == "B"] = "blue"
plot(g, vertex.label=NA)
# Now, color the vertices based on the school that each user in our network attended.
V(g)$color = "black"
V(g)$color[V(g)$school == "A"] = "red"
V(g)$color[V(g)$school == "B"] = "blue"
plot(g, vertex.label=NA)
# Now, color the vertices based on the school that each user in our network attended.
V(g)$color = "black"
V(g)$color[V(g)$school == "A"] = "red"
V(g)$color[V(g)$school == "AB"] = "yellow"
plot(g, vertex.label=NA)
# Now, color the vertices based on the school that each user in our network attended.
V(g)$color = "black"
V(g)$color[V(g)$school == "A"] = "red"
V(g)$color[V(g)$school == "AB"] = "gray"
plot(g, vertex.label=NA)
# Now, color the vertices based on the locale of the user.
V(g)$color = "black"
V(g)$color[V(g)$locale == "A"] = "red"
V(g)$color[V(g)$locale == "B"] = "gray"
plot(g, vertex.label=NA)
# Which igraph plotting function would enable us to plot our graph in 3-D?
?igraph
# Which igraph plotting function would enable us to plot our graph in 3-D?
?igraph.plotting
tweets = read.csv("tweets.csv", stringsAsFactors = FALSE)
tweets = read.csv("tweets.csv", stringsAsFactors = FALSE)
corpus = corpus(tweets$Tweet)
corpus = VCorpus(VectorSource(tweets$Tweet))
corpus = Corpus(VectorSource(tweets$Tweet))
library(NLP)
library(tm)
corpus = Corpus(VectorSource(tweets$Tweet))
corpus = VCorpus(VectorSource(tweets$Tweet))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
dtm = DocumentTermMatrix(corpus)
corpus = Corpus(VectorSource(tweets$Tweet))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
dtm = DocumentTermMatrix(corpus)
allTweets = as.data.frame(as.matrix(dtm))
allTweets
str(allTweets)
install.packages("wordcloud")
library(wordcloud)
colnames(allTweets)
rowSums(allTweets)
# Which function should we apply to allTweets to obtain the frequency of each word across all tweets?
colSums(allTweets)
# Use allTweets to build a word cloud. Make sure to check out the help page for wordcloud if you are not sure how to do this.
?wordcloud
wordcloud(colnames(allTweets), colSums(allTweets))
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2, 0.25))
# Repeat the steps to load and pre-process the corpus, this time removing the most frequent word in addition to all elements of stopwords("english")
# in the call to tm_map with removeWords.
corpus2 = Corpus(VectorSource(tweets$Tweet))
corpus2 = tm_map(corpus2, tolower)
corpus2 = tm_map(corpus2, removePunctuation)
corpus2 = tm_map(corpus2, removeWords, c("apple", stopwords("english")))
# Replace allTweets with the document-term matrix of this new corpus --
# we will use this updated corpus for the remainder of the assignment.
dtm2 = DocumentTermMatrix(corpus2)
allTweets = as.data.frame(as.matrix(dtm2))
str(allTweets)
# Create a word cloud with the updated corpus.
wordcloud(colnames(allTweets), colSums(allTweets), scale=c(2, 0.25))
# A word cloud that is only based on the negative tweets
negativeTweets = subset(allTweets, tweets$Avg <= -1)
wordcloud(colnames(negativeTweets), colSums(negativeTweets), scale=c(2, 0.25))
# Use allTweets to build a word cloud. Make sure to check out the help page for wordcloud if you are not sure how to do this.
?wordcloud
# The function brewer.pal() returns color palettes from the ColorBrewer project when provided with appropriate parameters,
# and the function display.brewer.all() displays the palettes we can choose from.
?display.brewer.all
display.brewer.pal(8, "Set2")
# The function brewer.pal() returns color palettes from the ColorBrewer project when provided with appropriate parameters,
# and the function display.brewer.all() displays the palettes we can choose from.
?display.brewer.all
display.brewer.pal(8, "Accent")
display.brewer.pal(9, "YlOrRd")
display.brewer.pal(9, "Greys")
# In sequential palettes, sometimes there is an undesirably large contrast between the lightest and darkest colors.
wordcloud(colors=brewer.pal(9, "Blues"))
# In sequential palettes, sometimes there is an undesirably large contrast between the lightest and darkest colors.
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "Blues"))
# Two possible commands to remove the first four color elements of the 9-color palette.
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "Blues")[-1:-4], scale=c(2, 0.25))
wordcloud(colnames(allTweets), colSums(allTweets), colors=brewer.pal(9, "Blues")[5:9], scale=c(2, 0.25))
wordcloud(colnames(allTweets), colSums(allTweets, min.freq=10, random.order=FALSE, colors=brewer.pal(9, "Purples")[5:9], ordered.colors=TRUE, scale=c(2, 0.25))
wordcloud(colnames(allTweets), colSums(allTweets, min.freq=10, random.order=FALSE, colors=brewer.pal(9, "Purples")[5:9], ordered.colors=TRUE, scale=c(2, 0.25)))
wordcloud(colnames(allTweets), colSums(allTweets, min.freq=10, random.order=FALSE, colors=brewer.pal(9, "Purples")[5:9], scale=c(2, 0.25))
wordcloud(colnames(allTweets), colSums(allTweets), min.freq=10, random.order=FALSE, colors=brewer.pal(9, "Purples")[5:9], ordered.colors=TRUE, scale=c(2, 0.25)))
wordcloud(colnames(allTweets), colSums(allTweets), min.freq=10, random.order=FALSE, colors=brewer.pal(9, "Purples")[5:9], ordered.colors=TRUE, scale=c(2, 0.25))
wordcloud(colnames(allTweets), colSums(allTweets), min.freq=10, random.order=FALSE, colors=brewer.pal(9, "Purples"), ordered.colors=TRUE, scale=c(2, 0.25))
wordcloud(colnames(allTweets), colSums(allTweets), random.order=FALSE, colors=brewer.pal(9, "Purples"), ordered.colors=TRUE, scale=c(2, 0.25))
wordcloud(colnames(allTweets), colSums(allTweets), random.order=FALSE, colors=brewer.pal(9, "Purples"), scale=c(2, 0.25))
wordcloud(colnames(allTweets), colSums(allTweets), random.order=FALSE, colors=brewer.pal(9, "Purples")[5:9], scale=c(2, 0.25))
wordcloud(colnames(allTweets), colSums(allTweets), min.freq=10, random.order=FALSE, colors=brewer.pal(9, "Purples")[5:9], scale=c(2, 0.25))
parole = read.csv("parole.csv")
parole$male = as.factor(parole$male)
parole$state = as.factor(parole$state)
parole$crime = as.factor(parole$crime)
1 - mean(parole$male)
mean(parole$male)
table(parole$male)
130 / (130 + 545)
table(parole$male, parole$violator)
table(parole$male == 0, parole$violator)
14 / (116 + 14)
14 / (64 + 14)
subset(parole, state == 2)
kentucky = subset(parole, state == 2)
table(kentucky$crime)
# Create a histogram to find out the distribution of the age of parolees
ggplot(data = parole, aes(x = age)) + geom_histogram(binwidth = 5, boundary = 0, color = 'black', fill = 'cornflowerblue')
# Redo the histogram, adding the following argument to the geom_histogram function: color="blue".
ggplot(data = parole, aes(x = age)) + geom_histogram(binwidth = 5, boundary = 0, color = 'blue', fill = 'cornflowerblue')
# Another option would be to stick with histograms, but to create a separate histogram for each gender.
ggplot(data = parole, aes(x = age)) + geom_histogram(binwidth = 5, boundary = 0) + facet_grid(male ~ .)
# Now change the facet_grid argument to be ".~male" instead of "male~."
ggplot(data = parole, aes(x = age)) + geom_histogram(binwidth = 5, boundary = 0) + facet_grid(. ~ male)
ggplot(data = parole, aes(x = age, fill = male)) + geom_histogram(binwidth = 5, boundary = 0)
colorPalette = c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
ggplot(data = parole, aes(x = age, fill = male)) +
geom_histogram(binwidth = 5, boundary = 0) +
scale_fill_manual(values=colorPalette)
ggplot(data = parole, aes(x = age, fill = male)) +
geom_histogram(binwidth = 5, boundary = 1) +
scale_fill_manual(values=colorPalette)
ggplot(data = parole, aes(x = age, fill = male)) +
geom_histogram(binwidth = 5, boundary = 10) +
scale_fill_manual(values=colorPalette)
ggplot(data = parole, aes(x = age, fill = male)) +
geom_histogram(binwidth = 5, boundary = 0) +
scale_fill_manual(values=colorPalette)
ggplot(data = parole, aes(x = age, fill = male)) +
geom_histogram(binwidth = 5, boundary = 0, position = "identity", alpha=0.5) +
scale_fill_manual(values=colorPalette)
# Now let's explore another aspect of the data: the amount of time served by parolees.
# Create a basic histogram like the one we created in Problem 2,
# but this time with time.served on the x-axis. Set the bin width to one month.
str(parole)
ggplot(data = parole, aes(x = time.served)) +
geom_histogram(binwidth = 1, boundary = 0, color = 'black', fill = 'cornflowerblue')
# Change the binwidth to 0.1 months.
ggplot(data = parole, aes(x = time.served)) +
geom_histogram(binwidth = 0.1, boundary = 0, color = 'black', fill = 'cornflowerblue')
# Now, suppose we suspect that it is unlikely that each type of crime has the same distribution of time served.
ggplot(data = parole, aes(x = time.served)) +
geom_histogram(binwidth = 1, boundary = 0, color = 'black', fill = 'cornflowerblue') +
facet_grid(. ~ crime)
# Now, instead of faceting the histograms, overlay them.
ggplot(data = parole, aes(x = time.served)) +
geom_histogram(binwidth = 0.1, boundary = 0, position = "identity", alpha = 0.5) +
scale_fill_manual(values=colorPalette)
# Now, instead of faceting the histograms, overlay them.
ggplot(data = parole, aes(x = crime)) +
geom_histogram(binwidth = 0.1, boundary = 0, position = "identity", alpha = 0.5) +
scale_fill_manual(values=colorPalette)
# Now, instead of faceting the histograms, overlay them.
ggplot(data = parole, aes(x = time.served, fill = crime)) +
geom_histogram(binwidth = 0.1, boundary = 0, position = "identity", alpha = 0.5) +
scale_fill_manual(values=colorPalette)
